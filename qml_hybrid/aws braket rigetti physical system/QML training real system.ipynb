{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089c060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453bdfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100727e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !touch ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c histopathologic-cancer-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76401ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88fcde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe2ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc31f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2808ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00758da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.ndimage as ndi\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c618e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "# import torchio as tio\n",
    "# from torchio import AFFINE, DATA\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.ndimage as ndi\n",
    "import shutil\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78fc989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "n_qubits = 4                # Number of qubits\n",
    "step = 0.000004               # Learning rate\n",
    "batch_size = 8              # Number of samples for each training step\n",
    "num_epochs = 25              # Number of training epochs\n",
    "q_depth = 1                 # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 0.01              # Initial spread of random quantum weights\n",
    "start_time = time.time()    # Start of the computation timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cc2787",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_arn = \"arn:aws:braket:us-west-1::device/qpu/rigetti/Aspen-M-3\"\n",
    "dev = qml.device('braket.aws.qubit', device_arn=device_arn, wires=n_qubits)\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a161713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a094355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install s3fs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c76fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a952ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b484ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='kaggle-cancer-dataset'\n",
    "data_key = 'train_labels.csv'\n",
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=data_key)\n",
    "#s3://kaggle-cancer-dataset/train_labels.csv\n",
    "\n",
    "train_data = pd.read_csv(obj['Body'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1f9ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_numpy = train_data.values\n",
    "print(train_data_numpy[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27229156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_val= train_test_split(train_data_numpy, test_size = 0.25, random_state=42,stratify=train_data_numpy[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644bb4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_numpy))\n",
    "print(len(data_train))\n",
    "print(len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "bucket1 = 'kaggle-cancer-dataset'\n",
    "key1 = \"train/00001b2b5609af42ab0ab276dd4cd41c3e7745b5.tif\"\n",
    "obj = s3.get_object(Bucket=bucket1, Key=key1)\n",
    "\n",
    "image_array = Image.open(obj['Body'])\n",
    "numpy_array = np.asarray(image_array)\n",
    "print(numpy_array.shape)\n",
    "plt.imshow(image_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data_train,columns=[\"id\",\"label\"])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.DataFrame(data_val,columns=[\"id\",\"label\"])\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38890069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('train_data_new.csv',index=False,header=False)\n",
    "df_val.to_csv('val_data_new.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82baa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send these file to s3 using terminal\n",
    "#https://www.middlewareinventory.com/blog/ec2-s3-copy/ -> commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa25f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker.session import TrainingInput\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "class Cancerclass(Dataset):\n",
    "    def __init__(self,csv_data,root_dir,key,transform=None):\n",
    "        self.bucket_name = root_dir\n",
    "        self.key = key\n",
    "        self.transform = transform\n",
    "        self.data = csv_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        filename = str(self.data[idx][0])\n",
    "        bucket1 = self.bucket_name\n",
    "        key1 = self.key +\"/\" + filename + '.tif'\n",
    "        obj = s3.get_object(Bucket=bucket1, Key=key1)\n",
    "\n",
    "        image_array = Image.open(obj['Body'])\n",
    "        image_array1 = image_array\n",
    "\n",
    "        del image_array\n",
    "       \n",
    "        label = int(self.data[idx][1])\n",
    "\n",
    "        if self.transform:\n",
    "            tensor_image = self.transform(image_array1)\n",
    "\n",
    "        return tensor_image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383033c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ea257",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451430a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_layer(nqubits):\n",
    "    \"\"\"Layer of single-qubit Hadamard gates.\n",
    "    \"\"\"\n",
    "    for idx in range(nqubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "\n",
    "\n",
    "def RY_layer(w):\n",
    "    \"\"\"Layer of parametrized qubit rotations around the y axis.\n",
    "    \"\"\"\n",
    "    for idx, element in enumerate(w):\n",
    "        qml.RY(element, wires=idx)\n",
    "\n",
    "def U_layer(w):\n",
    "    \"\"\"Layer of parametrized qubit rotations around the y axis.\n",
    "    \"\"\"\n",
    "    for idx, element in enumerate(w):\n",
    "        qml.U3(element[0],element[1],element[2],wires=idx)\n",
    "        \n",
    "def entangling_layer1(nqubits):\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    qml.CNOT(wires=[2,3])\n",
    "    qml.CNOT(wires=[1,2])\n",
    "    qml.CNOT(wires=[0,3])\n",
    "\n",
    "def entangling_layer(nqubits):\n",
    "    \"\"\"Layer of CNOTs followed by another shifted layer of CNOT.\n",
    "    \"\"\"\n",
    "    # In other words it should apply something like :\n",
    "    # CNOT  CNOT  CNOT  CNOT...  CNOT\n",
    "    #   CNOT  CNOT  CNOT...  CNOT\n",
    "    for i in range(0, nqubits - 1, 2):  # Loop over even indices: i=0,2,...N-2\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    for i in range(1, nqubits - 1, 2):  # Loop over odd indices:  i=1,3,...N-3\n",
    "        qml.CNOT(wires=[i, i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0256fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_net(q_input_features, q_weights_flat):\n",
    "    \"\"\"\n",
    "    The variational quantum circuit.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape weights\n",
    "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
    "\n",
    "    # Start from state |+> , unbiased w.r.t. |0> and |1>\n",
    "    H_layer(n_qubits)\n",
    "\n",
    "    # Embed features in the quantum node\n",
    "    RY_layer(q_input_features)\n",
    "\n",
    "    # # # Sequence of trainable variational layers\n",
    "    for k in range(q_depth):\n",
    "        qml.BasicEntanglerLayers(weights=q_weights, wires=range(n_qubits))\n",
    "    \n",
    "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)]\n",
    "    return tuple(exp_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7844dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DressedQuantumNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Torch module implementing the *dressed* quantum net.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Definition of the *dressed* layout.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.pre_net = nn.Linear(512, n_qubits)\n",
    "        self.q_params = nn.Parameter(q_delta * torch.rand(q_depth * n_qubits)) # 2 for QAOA //rand\n",
    "        self.post_net = nn.Linear(n_qubits, 2)\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        \"\"\"\n",
    "        Defining how tensors are supposed to move through the *dressed* quantum\n",
    "        net.\n",
    "        \"\"\"\n",
    "\n",
    "        # obtain the input features for the quantum circuit\n",
    "        # by reducing the feature dimension from 512 to 4\n",
    "        pre_out = self.pre_net(input_features)\n",
    "        q_in = torch.tanh(pre_out) * np.pi / 2.0\n",
    "\n",
    "        # Apply the quantum circuit to each element of the batch and append to q_out\n",
    "        q_out = torch.Tensor(0, n_qubits)\n",
    "        q_out = q_out.to(device)\n",
    "        for elem in q_in:\n",
    "            q_out_elem = quantum_net(elem, self.q_params).float().unsqueeze(0)\n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "\n",
    "        # return the two-dimensional prediction from the postprocessing layer\n",
    "        return self.post_net(q_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid = models.resnet18(pretrained=True)\n",
    "model_hybrid.fc = DressedQuantumNet()\n",
    "model_hybrid = model_hybrid.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_set = Cancerclass(data_train,'kaggle-cancer-dataset',\"train\",transforms.Compose(\n",
    "    [transforms.ToTensor()]))\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "test_set = Cancerclass(data_val, 'kaggle-cancer-dataset',\"train\", transforms.Compose([transforms.ToTensor()]))\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model_hybrid.parameters(),lr=1E-5)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "    opt, step_size=10, gamma=gamma_lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader,model):\n",
    "    with torch.no_grad():\n",
    "        total,correct = 0,0\n",
    "        for data in dataloader:\n",
    "            inputs,labels = data\n",
    "            inputs,labels = inputs.to(device),labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _,pred = torch.max(outputs.data,1) \n",
    "            total += labels.size(0)\n",
    "            correct += (pred==labels).sum().item()\n",
    "\n",
    "        return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa493279",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_arr = []\n",
    "epoch_loss_arr = []\n",
    "epoch_acc = []\n",
    "import copy\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    print(\"Training started:\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader,0):\n",
    "            print(i)\n",
    "            inputs, labels = data\n",
    "            batch_size_ = len(inputs)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_arr.append(loss.item())\n",
    "        \n",
    "\n",
    "        epoch_loss_arr.append(loss.item())\n",
    "        epoch_acc.append(evaluation(train_loader,model))\n",
    "        print(model.fc.q_params)\n",
    "        print(\n",
    "                    \"Epoch: {}/{} Train Loss: {:.4f} Train Acc: {:.4f} Val Acc: {:.4f} \".format(\n",
    "                        epoch,\n",
    "                        num_epochs,\n",
    "                        epoch_loss_arr[-1],\n",
    "                        epoch_acc[-1],\n",
    "                        evaluation(val_loader,model)\n",
    "                    )\n",
    "                )\n",
    "        PATH = '/content/' + 'model_' + str(epoch) + '.pt'\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': opt.state_dict(),\n",
    "                'loss': loss.item(),\n",
    "                }, PATH)\n",
    "          #best_model_wts = copy.deepcopy(model.state_dict())\n",
    "          # Update learning rate\n",
    "        scheduler.step()\n",
    "      #model.load_state_dict(best_model_wts)\n",
    "       \n",
    "    # Print final results\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d670f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid = train_model(\n",
    "    model_hybrid, loss_fn, opt, exp_lr_scheduler, num_epochs=25\n",
    ")\n",
    "\n",
    "plt.plot(epoch_loss_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# loss_arr = []\n",
    "# loss_epoch_arr = []\n",
    "# max_epochs = 25\n",
    "\n",
    "# for epoch in tqdm(range(max_epochs)):\n",
    "#     for i, data in enumerate(train_loader,0):\n",
    "#         inputs, labels = data\n",
    "#         inputs,labels = inputs.to(device),labels.to(device)\n",
    "#         opt.zero_grad()\n",
    "\n",
    "#         outputs = model(inputs)\n",
    "#         _,pred_labels = torch.max(outputs.data,1)\n",
    "#         loss = loss_fn(outputs,labels)\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         del inputs,labels\n",
    "\n",
    "#         loss_arr.append(loss.item())\n",
    "\n",
    "# #     PATH = '/content/' + 'model_' + str(epoch) + '.pt'\n",
    "  \n",
    "  \n",
    "#     loss_epoch_arr.append(loss.item())\n",
    "#     print('Epoch = %d/%d, Train Acc: %0.2f, Test Acc: %0.2f '%(epoch,max_epochs,evaluation(train_loader),\n",
    "#         evaluation(test_loader)))\n",
    "# #     torch.save({\n",
    "# #             'epoch': epoch,\n",
    "# #             'model_state_dict': model.state_dict(),\n",
    "# #             'optimizer_state_dict': opt.state_dict(),\n",
    "# #             'loss': loss.item(),\n",
    "# #             }, PATH)\n",
    "\n",
    "\n",
    "# plt.plot(loss_epoch_arr)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "# from sagemaker.debugger import Rule, rule_configs\n",
    "# from sagemaker.session import TrainingInput\n",
    "\n",
    "# region = sagemaker.Session().boto_region_name\n",
    "# print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "# role = sagemaker.get_execution_role()\n",
    "# print(\"RoleArn: {}\".format(role))\n",
    "\n",
    "# s3_output_location='s3://{}/{}/{}'.format('kaggle-cancer-dataset', 'models', 'xgboost_model')\n",
    "\n",
    "# container=sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n",
    "# print(container)\n",
    "\n",
    "# xgb_model=sagemaker.estimator.Estimator(\n",
    "#     image_uri=container,\n",
    "#     role=role,\n",
    "#     instance_count=1,\n",
    "#     instance_type='ml.m4.xlarge',\n",
    "#     volume_size=5,\n",
    "#     output_path=s3_output_location,\n",
    "#     sagemaker_session=sagemaker.Session(),\n",
    "#     rules=[Rule.sagemaker(rule_configs.create_xgboost_report())]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c90415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model.set_hyperparameters(\n",
    "#     max_depth = 5,\n",
    "#     eta = 0.2,\n",
    "#     gamma = 4,\n",
    "#     min_child_weight = 6,\n",
    "#     subsample = 0.7,\n",
    "#     objective = \"binary:logistic\",\n",
    "#     num_round = 1000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29efee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.session import TrainingInput\n",
    "\n",
    "# train_input = TrainingInput(\n",
    "#     \"s3://{}/{}\".format('kaggle-cancer-dataset', \"train_data_new.csv\"), content_type=\"csv\"\n",
    "# )\n",
    "# validation_input = TrainingInput(\n",
    "#     \"s3://{}/{}\".format('kaggle-cancer-dataset',\"val_data_new.csv\"), content_type=\"csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model.fit({\"train\": train_input, \"validation\": validation_input}, wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_braket",
   "language": "python",
   "name": "conda_braket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
