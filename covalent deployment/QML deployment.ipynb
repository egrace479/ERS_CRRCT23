{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef849671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ram/Anaconda/anaconda3/envs/covalent/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Pennylane\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OpenMP: number of parallel threads.\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8de1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, models\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.ndimage as ndi\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4d1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import covalent as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1522d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 5\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "558f00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def H_layer(nqubits):\n",
    "    \"\"\"Layer of single-qubit Hadamard gates.\n",
    "    \"\"\"\n",
    "    for idx in range(nqubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "\n",
    "@ct.electron\n",
    "def RY_layer(w):\n",
    "    \"\"\"Layer of parametrized qubit rotations around the y axis.\n",
    "    \"\"\"\n",
    "    for idx, element in enumerate(w):\n",
    "        qml.RY(element, wires=idx)\n",
    "\n",
    "@ct.electron\n",
    "def entangling_layer(nqubits):\n",
    "    \"\"\"Layer of CNOTs followed by another shifted layer of CNOT.\n",
    "    \"\"\"\n",
    "    # In other words it should apply something like :\n",
    "    # CNOT  CNOT  CNOT  CNOT...  CNOT\n",
    "    #   CNOT  CNOT  CNOT...  CNOT\n",
    "    for i in range(0, nqubits - 1, 2):  # Loop over even indices: i=0,2,...N-2\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    for i in range(1, nqubits - 1, 2):  # Loop over odd indices:  i=1,3,...N-3\n",
    "        qml.CNOT(wires=[i, i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd3fdbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "@qml.qnode(dev, interface=\"torch\",diff_method=\"adjoint\")\n",
    "def quantum_net(q_input_features, q_weights_flat):\n",
    "    \"\"\"\n",
    "    The variational quantum circuit.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape weights\n",
    "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
    "\n",
    "    # Start from state |+> , unbiased w.r.t. |0> and |1>\n",
    "    H_layer(n_qubits)\n",
    "\n",
    "    # Embed features in the quantum node\n",
    "    RY_layer(q_input_features)\n",
    "\n",
    "    # # # Sequence of trainable variational layers\n",
    "    for k in range(q_depth):\n",
    "        qml.BasicEntanglerLayers(weights=q_weights, wires=range(n_qubits))\n",
    "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)]\n",
    "    return tuple(exp_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54663fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_depth = 1                 # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 0.01              # Initial spread of random quantum weights\n",
    "start_time = time.time()    # Start of the computation timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37fb527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "class DressedQuantumNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Torch module implementing the *dressed* quantum net.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Definition of the *dressed* layout.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.pre_net = nn.Linear(512, n_qubits)\n",
    "        self.q_params = nn.Parameter(q_delta * torch.zeros(q_depth * n_qubits)) # 2 for QAOA //rand\n",
    "        self.post_net = nn.Linear(n_qubits, 2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        \"\"\"\n",
    "        Defining how tensors are supposed to move through the *dressed* quantum\n",
    "        net.\n",
    "        \"\"\"\n",
    "\n",
    "        # obtain the input features for the quantum circuit\n",
    "        # by reducing the feature dimension from 512 to 4\n",
    "        pre_out = self.pre_net(input_features)\n",
    "        q_in = self.relu(pre_out) * np.pi / 2.0\n",
    "\n",
    "        # Apply the quantum circuit to each element of the batch and append to q_out\n",
    "        q_out = torch.Tensor(0, n_qubits)\n",
    "        q_out = q_out.to(device)\n",
    "        for elem in q_in:\n",
    "            q_out_elem = quantum_net(elem, self.q_params).float().unsqueeze(0)\n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "\n",
    "        # return the two-dimensional prediction from the postprocessing layer\n",
    "        return self.post_net(q_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a192ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_hybrid = models.resnet18(pretrained=True)\n",
    "model_hybrid.fc = DressedQuantumNet()\n",
    "model_hybrid = model_hybrid.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73ea8e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hybrid.load_state_dict(torch.load('./model_14.pt',map_location=torch.device('cpu'))['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72df2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def evaluation(dataloader,model):\n",
    "    arr = []\n",
    "    with torch.no_grad():\n",
    "        total,correct = 0,0\n",
    "        for data in dataloader:\n",
    "            inputs,labels = data\n",
    "            inputs,labels = inputs.to(device),labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _,pred = torch.max(outputs.data,1) \n",
    "             # pred = pred + 1\n",
    "            print(pred)\n",
    "            total += labels.size(0)\n",
    "            correct += (pred==labels).sum().item()\n",
    "            arr.append(pred)\n",
    "\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe5edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from PIL import Image \n",
    "#import skimage.transform as skTrans\n",
    "@ct.electron\n",
    "class CancerClass(Dataset):\n",
    "    def __init__(self,csv_data_x,csv_data_y,root_dir,transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.datax = csv_data_x\n",
    "        self.datay = csv_data_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datax)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        filename = str(self.datax[idx])\n",
    "        img_path = self.root_dir +'/'+ filename + '.tif'\n",
    "\n",
    "        image_array = Image.open(img_path)\n",
    "        image_array1 = image_array\n",
    "\n",
    "        del image_array\n",
    "\n",
    "        label = int(self.datay[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            tensor_image = self.transform(image_array1)\n",
    "\n",
    "        return tensor_image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d39ed0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_new_x = ['0000d563d5cfafc4e68acb7c9829258a298d9b6a','0000da768d06b879e5754c43e2298ce48726f722','0000f8a4da4c286eee5cf1b0d2ab82f979989f7b','000a2a35668f04edebc0b06d5d133ad90c93a044','000aa5d8f68dc1f45ebba53b8f159aae80e06072','000aa7c34dc319d936d36f7f4c257812d3d03cdf','000aa638312a3dad22ef04b8a7df3fc98fc2e7c3','000af35befdd9ab2e24fac80fb6508dfd1edd172','000b35e7c39c6cb32224dcb3fe4c48acf34f0252','000b666f7b5f03e81937cb12b3a1c8c279b08292','000c3d0468a1a0a7a35a2e453f4b891b3a4e7fb6','000c4f225ec3f4d1eaa986d75596cc71e10568b6','000d3de1f31201b54cf82572c10099606f33c791','000d4bcc9d239e8304890ffd764794e93504e475']\n",
    "val_data_new_y = [0,1,0,1,1,1,0,1,1,0,1,0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "741f518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "val_set = CancerClass(val_data_new_x,val_data_new_y,'/home/ram/new_temp/Images',transforms.Compose(\n",
    "    [transforms.ToTensor()]))\n",
    "val_loader = torch.utils.data.DataLoader(val_set,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "531e9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.lattice\n",
    "def workflow(model,dataloader):\n",
    "    val = evaluation(dataloader,model)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcd7acd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1]), tensor([0]), tensor([1]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([1]), tensor([1]), tensor([0]), tensor([1]), tensor([1]), tensor([0]), tensor([0])]\n"
     ]
    }
   ],
   "source": [
    "dispatch_id = ct.dispatch(workflow)(model_hybrid, val_loader)\n",
    "result = ct.get_result(dispatch_id=dispatch_id, wait=True)\n",
    "val = result.result\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd381e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([1]),\n",
       " tensor([0]),\n",
       " tensor([1]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([0]),\n",
       " tensor([1]),\n",
       " tensor([1]),\n",
       " tensor([0]),\n",
       " tensor([1]),\n",
       " tensor([1]),\n",
       " tensor([0]),\n",
       " tensor([0])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(val_loader,model_hybrid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:covalent] *",
   "language": "python",
   "name": "conda-env-covalent-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
